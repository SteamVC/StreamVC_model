{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StreamVC Training on Google Colab\n",
    "\n",
    "このノートブックでは、Google Colab上でStreamVCの学習を実行します。\n",
    "\n",
    "## 前提条件\n",
    "- Google Driveに`streamVC/data/`がアップロード済み\n",
    "- GitHubリポジトリが公開されている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Driveをマウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. リポジトリのクローン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# GitHubリポジトリのURL（あなたのリポジトリに変更してください）\nREPO_URL = \"https://github.com/SteamVC/StreamVC_model.git\"\n\n!git clone {REPO_URL}\n%cd StreamVC_model"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 依存パッケージのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e . -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. キャッシュ生成（初回のみ / 修正後の再生成時）\n\nGoogle Drive の生データから、修正版 whitening を適用したキャッシュを生成して Google Drive に保存します。\n\n**既にキャッシュがある場合はスキップしてください。**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import subprocess\nfrom pathlib import Path\n\n# Google Drive のキャッシュパス\nGDRIVE_CACHE = \"/content/drive/MyDrive/streamVC/data/cache/libri_tts\"\n\n# キャッシュが既に存在するかチェック\ndef count_cache_files(path):\n    try:\n        result = subprocess.run(\n            f\"ls -1 '{path}/train' 2>/dev/null | wc -l\",\n            shell=True, capture_output=True, text=True\n        )\n        return int(result.stdout.strip())\n    except:\n        return 0\n\nexisting_count = count_cache_files(GDRIVE_CACHE)\nprint(f\"既存キャッシュ: {existing_count} files\")\n\nif existing_count > 30000:\n    print(\"✓ キャッシュは既に存在します\")\n    print(\"  修正版で再生成する場合は、次のセルを実行してください\")\nelse:\n    print(\"⚠ キャッシュが不足しています\")\n    print(\"  次のセルでキャッシュを生成してください\")"
  },
  {
   "cell_type": "code",
   "source": "# Whitening の漏れをチェック\n!python scripts/check_whitening_leak.py\n\nprint(\"\\n期待される結果:\")\nprint(\"  F0 各サンプル平均の分散: ≈ 0.000 (修正前: 0.339)\")\nprint(\"  Energy 各サンプル平均の分散: ≈ 0.000 (修正前: 0.431)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.2. Whitening 検証\n\n生成したキャッシュで per-utterance whitening が正しく機能しているか確認します。",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# キャッシュ生成（Google Drive に直接保存）\nprint(\"=\" * 60)\nprint(\"キャッシュ生成開始（修正版 per-utterance whitening）\")\nprint(\"=\" * 60)\n\n# Config を使ってキャッシュ生成\n!python scripts/preprocess.py \\\n    --config configs/colab_cache_gen.yaml \\\n    --device cuda \\\n    --batch-size 32\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"キャッシュ生成完了\")\nprint(\"=\" * 60)\n\n# 生成されたファイル数を確認\ntrain_count = count_cache_files(GDRIVE_CACHE)\nprint(f\"生成されたキャッシュ: {train_count} files\")\n\nif train_count > 30000:\n    print(\"✓ キャッシュ生成成功\")\nelse:\n    print(\"⚠ キャッシュが不足しています（エラーが発生した可能性）\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.1. キャッシュ生成実行\n\n**注意**: これには 30-60分 かかります。GPU を使用します。",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Checkpointディレクトリの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Checkpoint保存先をGoogle Driveに設定（正しいパス）\nCHECKPOINT_DIR = \"/content/drive/MyDrive/streamVC/checkpoints\"\n\n!mkdir -p {CHECKPOINT_DIR}\n\nprint(f\"Checkpoints will be saved to: {CHECKPOINT_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 設定ファイルの準備（Colab用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab用の設定ファイルを確認\n",
    "!cat configs/colab_gpu_training.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 7.5. DataLoader動作確認（学習前に実行推奨）\n\n学習がハングする問題を診断するため、DataLoaderの動作をテストします。",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import time\nimport torch\nimport sys\nfrom pathlib import Path\n\n# 作業ディレクトリがStreamVC_modelであることを確認\nimport os\nif not os.path.exists(\"configs/colab_gpu_training.yaml\"):\n    print(\"エラー: StreamVC_modelディレクトリにいません\")\n    print(\"セル6 (リポジトリのクローン) を実行してください\")\n    raise RuntimeError(\"Wrong directory\")\n\n# srcディレクトリをPythonパスに追加\nsys.path.insert(0, str(Path.cwd() / \"src\"))\n\nfrom streamvc.config import load_config\nfrom streamvc.data.dataset import build_dataloader\n\nprint(\"=\" * 60)\nprint(\"DataLoader動作確認スクリプト\")\nprint(\"=\" * 60)\n\n# Config読み込み\nconfig_path = \"configs/colab_gpu_training.yaml\"\nprint(f\"\\n1. Config読み込み: {config_path}\")\ncfg = load_config(config_path)\nprint(f\"   ✓ Batch size: {cfg.training.batch_size}\")\nprint(f\"   ✓ Sample rate: {cfg.data.sample_rate}\")\n\n# DataLoader構築（時間計測）\nprint(\"\\n2. DataLoader構築中...\")\nstart = time.time()\ntry:\n    train_loader = build_dataloader(cfg, split=\"train\", batch_size=cfg.training.batch_size)\n    build_time = time.time() - start\n    print(f\"   ✓ 構築完了: {build_time:.2f}秒\")\nexcept Exception as e:\n    print(f\"   ✗ エラー: {e}\")\n    raise\n\n# 最初のバッチをロード（時間計測）\nprint(\"\\n3. 最初のバッチをロード中...\")\nstart = time.time()\ntry:\n    batch = next(iter(train_loader))\n    load_time = time.time() - start\n    print(f\"   ✓ ロード完了: {load_time:.2f}秒\")\n    \n    # バッチの内容を確認\n    print(\"\\n4. バッチの内容:\")\n    for key, value in batch.items():\n        if isinstance(value, torch.Tensor):\n            print(f\"   - {key}: shape={value.shape}, dtype={value.dtype}\")\n        else:\n            print(f\"   - {key}: {type(value)}\")\n    \nexcept Exception as e:\n    print(f\"   ✗ エラー: {e}\")\n    import traceback\n    traceback.print_exc()\n    raise\n\n# 診断結果\nprint(\"\\n\" + \"=\" * 60)\nprint(\"診断結果:\")\nprint(\"=\" * 60)\nif load_time < 5:\n    print(f\"✓ DataLoaderは正常動作しています（{load_time:.2f}秒）\")\nelif load_time < 30:\n    print(f\"⚠ DataLoaderが遅いです（{load_time:.2f}秒）\")\n    print(\"  Google Driveからの読み込みが遅い可能性があります\")\nelse:\n    print(f\"✗ DataLoaderが非常に遅いです（{load_time:.2f}秒）\")\n    print(\"  Google Driveのマウントまたはキャッシュファイルに問題がある可能性があります\")\n    print(\"  対策: データをローカル（/content/）にコピーすることを推奨\")\n\nprint(\"\\n次のステップ: 問題なければ「8. 学習の実行」に進んでください\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7.6. データをローカルにコピー（高速化のため必須）\n\n診断結果でDataLoaderが遅い場合、Google Driveからローカルストレージにデータをコピーします。\nこれにより学習速度が大幅に改善されます（15分 → 数秒）。",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from pathlib import Path\nimport subprocess\n\n# Google Driveのキャッシュパス\nGDRIVE_CACHE = \"/content/drive/MyDrive/streamVC/data/cache\"\nLOCAL_DATA = \"/content/data\"\nLOCAL_CACHE = f\"{LOCAL_DATA}/cache\"\n\nprint(\"キャッシュをローカルにコピー中...\")\nprint(f\"コピー元: {GDRIVE_CACHE}\")\nprint(f\"コピー先: {LOCAL_CACHE}\")\n\n# ファイル数をlsで取得（globより高速）\ndef count_files(path):\n    try:\n        result = subprocess.run(\n            f\"ls -1 '{path}' 2>/dev/null | wc -l\",\n            shell=True, capture_output=True, text=True\n        )\n        return int(result.stdout.strip())\n    except:\n        return 0\n\n# Google Drive側のファイル数を取得\ngdrive_train_count = count_files(f\"{GDRIVE_CACHE}/libri_tts/train\")\ngdrive_valid_count = count_files(f\"{GDRIVE_CACHE}/libri_tts/valid\")\nprint(f\"\\nGoogle Drive側: train={gdrive_train_count}, valid={gdrive_valid_count}\")\n\n# ローカル側のファイル数を確認\nlocal_train_count = count_files(f\"{LOCAL_CACHE}/libri_tts/train\")\nlocal_valid_count = count_files(f\"{LOCAL_CACHE}/libri_tts/valid\")\nprint(f\"ローカル側: train={local_train_count}, valid={local_valid_count}\")\n\n# trainが不足している場合はコピー\nif local_train_count < gdrive_train_count:\n    print(f\"\\ntrainデータが不足しています ({local_train_count}/{gdrive_train_count})\")\n    \n    # tarファイルが存在するか確認（事前に作成済みなら高速）\n    tar_path = \"/content/drive/MyDrive/streamVC/data/cache.tar\"\n    if Path(tar_path).exists():\n        print(f\"✓ tarファイルが見つかりました: {tar_path}\")\n        print(\"tarから展開します（高速）...\")\n        !mkdir -p {LOCAL_DATA}\n        !tar -xf {tar_path} -C {LOCAL_DATA}/\n    else:\n        print(\"tarファイルがないため、rsyncでコピーします...\")\n        print(\"(次回高速化のため、後でtarファイルを作成することを推奨)\")\n        !mkdir -p {LOCAL_CACHE}/libri_tts/train\n        !mkdir -p {LOCAL_CACHE}/libri_tts/valid\n        !mkdir -p {LOCAL_CACHE}/hubert\n        !rsync -ah --progress --ignore-existing {GDRIVE_CACHE}/ {LOCAL_CACHE}/\n    \n    # 再カウント\n    local_train_count = count_files(f\"{LOCAL_CACHE}/libri_tts/train\")\n    local_valid_count = count_files(f\"{LOCAL_CACHE}/libri_tts/valid\")\n    print(f\"\\nコピー後: train={local_train_count}, valid={local_valid_count}\")\nelse:\n    print(f\"\\n✓ キャッシュは既にコピー済みです\")\n\n# シンボリックリンクを更新\nimport shutil\nif Path(\"data\").is_symlink():\n    Path(\"data\").unlink()\nelif Path(\"data\").exists():\n    shutil.rmtree(\"data\")\nPath(\"data\").symlink_to(LOCAL_DATA)\n\nprint(f\"✓ data/ -> {LOCAL_DATA} にリンク\")\n!du -sh {LOCAL_CACHE}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7.7. DataLoader動作再確認（ローカルコピー後）\n\nローカルにコピーした後、DataLoaderの速度を再確認します。",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import time\nimport torch\nimport sys\nfrom pathlib import Path\n\n# srcディレクトリをPythonパスに追加\nsys.path.insert(0, str(Path.cwd() / \"src\"))\n\nfrom streamvc.config import load_config\nfrom streamvc.data.dataset import build_dataloader\n\nprint(\"=\" * 60)\nprint(\"DataLoader速度再確認（ローカルコピー後）\")\nprint(\"=\" * 60)\n\n# Config読み込み\nconfig_path = \"configs/colab_gpu_training.yaml\"\ncfg = load_config(config_path)\n\n# DataLoader構築\nprint(\"\\nDataLoader構築中...\")\nstart = time.time()\ntrain_loader = build_dataloader(cfg, split=\"train\", batch_size=cfg.training.batch_size)\nbuild_time = time.time() - start\nprint(f\"✓ 構築完了: {build_time:.2f}秒\")\n\n# 最初のバッチをロード\nprint(\"\\n最初のバッチをロード中...\")\nstart = time.time()\nbatch = next(iter(train_loader))\nload_time = time.time() - start\nprint(f\"✓ ロード完了: {load_time:.2f}秒\")\n\n# 診断結果\nprint(\"\\n\" + \"=\" * 60)\nif load_time < 5:\n    print(f\"✓ 高速化成功！ DataLoaderは正常動作しています（{load_time:.2f}秒）\")\n    print(\"  学習を開始できます\")\nelif load_time < 30:\n    print(f\"⚠ まだ少し遅いです（{load_time:.2f}秒）\")\nelse:\n    print(f\"✗ まだ非常に遅いです（{load_time:.2f}秒）\")\n    print(\"  問題が解決していません\")\n\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 学習の実行\n",
    "\n",
    "### オプション1: インタラクティブ実行（ノートブック内で実行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 学習を開始（Ctrl+Cで中断可能）\n!python scripts/train.py \\\n    --config configs/colab_gpu_training.yaml \\\n    --device cuda \\\n    --gdrive-backup /content/drive/MyDrive/streamVC/checkpoints"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オプション2: バックグラウンド実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# バックグラウンドで学習を実行\n!nohup python scripts/train.py \\\n    --config configs/colab_gpu_training.yaml \\\n    --device cuda \\\n    --gdrive-backup /content/drive/MyDrive/streamVC/checkpoints \\\n    > train.log 2>&1 &\n\nprint(\"Training started in background\")\nprint(\"Check progress: !tail -20 train.log\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 学習の監視"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ログの確認\n",
    "!tail -30 train.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# TensorBoard起動\n%load_ext tensorboard\n%tensorboard --logdir runs/streamvc_colab_gpu/logs"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Checkpointの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存されたCheckpointを確認\n",
    "!ls -lh {CHECKPOINT_DIR}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 学習の再開（セッション切断後）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 最新のCheckpointから再開\nimport glob\n\nCHECKPOINT_DIR = \"/content/drive/MyDrive/streamVC/checkpoints\"\ncheckpoints = sorted(glob.glob(f\"{CHECKPOINT_DIR}/step_*.pt\"))\nif checkpoints:\n    latest_ckpt = checkpoints[-1]\n    print(f\"Resuming from: {latest_ckpt}\")\n    \n    !python scripts/train.py \\\n        --config configs/colab_gpu_training.yaml \\\n        --device cuda \\\n        --gdrive-backup /content/drive/MyDrive/streamVC/checkpoints \\\n        --resume {latest_ckpt}\nelse:\n    print(\"No checkpoint found. Starting from scratch.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "### セッション切断対策\n",
    "- Colabは最大12時間（無料版）または24時間（Pro）で切断されます\n",
    "- Checkpointは自動的にGoogle Driveに保存されるので安全です\n",
    "- 再接続後、「11. 学習の再開」から続行できます\n",
    "\n",
    "### メモリ不足の場合\n",
    "```yaml\n",
    "# configs/colab_gpu_training.yaml\n",
    "training:\n",
    "  batch_size: 8  # 16 → 8に減らす\n",
    "```\n",
    "\n",
    "### データセットの追加\n",
    "1. ローカルで新しいデータセットをダウンロード\n",
    "2. `./scripts/upload_dataset_to_gdrive.sh`で追加アップロード\n",
    "3. Configファイルに追加して再学習"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}