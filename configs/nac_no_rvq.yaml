experiment:
  name: nac_no_rvq_sanity
  seed: 1234

data:
  sample_rate: 16000
  frame_ms: 20.0
  lookahead_frames: 3
  cache_dir: data/cache
  datasets:
    - name: libri_tts
      root: data/libritts
      language: en
      metadata: data/libritts/metadata.jsonl
      weight: 1.0
  sample_length_sec: 1.28
  reference_length_sec: 1.0
  hubert_cache: data/cache/hubert
  yin_cache: data/cache/yin

model:
  num_hubert_labels: 100
  content_encoder:
    channels: 64
    latent_dim: 64
    num_layers: 6
    kernel_size: 7
    stride_schedule: [2, 2, 2]
    dilation_growth: 2
    dropout: 0.1
  speaker_encoder:
    channels: 32
    latent_dim: 64
    num_layers: 6
    kernel_size: 5
    stride_schedule: [2, 2]
    dilation_growth: 2
  decoder:
    channels: 40
    latent_dim: 64
    upsample_factors: [2, 2, 2]
    kernel_size: 7
    num_residual_blocks: 3
    rvq:
      num_quantizers: 0  # RVQ disabled for sanity check
      codebook_size: 1024
      dims: 40
      commitment_cost: 0.25
      progressive_steps: 999999
      use_ema: false
      use_cosine_sim: false
      use_ste_fix: true

training:
  batch_size: 16
  num_steps: 10000  # Quick sanity check
  optimizer:
    type: adamw
    lr: 0.0003
    betas: [0.8, 0.99]
    weight_decay: 0.01
  scheduler:
    type: cosine
    warmup_steps: 1000
    eta_min: 0.00001
  losses:
    content_ce_weight: 1.0
    stft_weight: 1.0
    l1_weight: 10.0
    adversarial_weight: 0.0
    feature_matching_weight: 0.0
    rms_weight: 1.0
    multiband_rms_weight: 0.5
  gradient_clip_norm: 1.0
  log_interval: 50
  eval_interval: 2000
  ckpt_interval: 5000
  output_dir: runs/nac_no_rvq_sanity
  use_amp: true
  gan_warmup_steps: 999999
  gan_rampup_steps: 0

inference:
  chunk_ms: 20.0
  quantize: false
  export:
    tflite: false
    onnx: false
